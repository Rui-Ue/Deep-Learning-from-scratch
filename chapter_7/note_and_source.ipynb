{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ７章  畳み込みニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### これまでのシンプルな NN の限界\n",
    "\n",
    "\n",
    "- アーキテクチャは「Affine - Activate - ... - Affine - Activate - Affine - Final Activate」という並び\n",
    "- Affine レイヤの入力はベクトル (ランク1テンソル) なので、各ピクセルの輝度値の行列 (カラーならランク3テンソル) を vec で潰してベクトルにして、扱うしかない。\n",
    "- よって、このシンプルな NN では入力画像データの形状に関する情報 (隣り合うピクセルの輝度値はどれか、RGBのどの輝度値か) を使うことはできない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 何が問題か？\n",
    "\n",
    "- Affine レイヤによって作られる各特徴量は「入力変数を全て使った (全ての入力変数を線形結合した)」ものである。\n",
    "- その意味で「全結合 (fully-connected) レイヤ」と呼ばれたりもする。\n",
    "- 学習がとてもうまくいけば「形状情報を考慮した特徴量」が勝手に作られるかもしれない。だが、fully-connected を想定したモデルなので、NN からすると各入力変数の位置関係は分からないので、なかなか難しい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### じゃあどうするか？\n",
    "\n",
    "- fully-connected で学習に任せるのではなく、明示的 (強制的) に「位置的に近いピクセルだけをもとに作られる特徴量」をモデルに仮定しておく。\n",
    "- 例えば、何らかの「画像処理におけるフィルタリングやプーリング」をするレイヤをネットワークに追加すれば、強制的に「形状情報を考慮した特徴量」が作られることになる。\n",
    "- どういうフィルタリングをするか、という内容についてはパラメータとして学習させる。\n",
    "\n",
    "平均プーリング：[参考](https://tech-blog.s-yoshiki.com/entry/123)\n",
    "![fig](https://images-tech-blog.s-yoshiki.com/img/2019/05/20190518004055.png)\n",
    "\n",
    "ソーベルフィルタ：[参考](https://imagingsolution.net/imaging/filter-algorithm/)\n",
    "![fig](https://imagingsolution.net/wordpress/wp-content/uploads/2011/03/blog163_10_median7_71.png)![fig](https://imagingsolution.net/wordpress/wp-content/uploads/2011/03/blog163_11.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フィルタリングするための畳み込み層\n",
    "\n",
    "- CNN では「畳み込み演算」をモデルに仮定 (ネットワークにレイヤ追加) することで、画像処理のフィルタリングを組み込んでいる。\n",
    "- 演算の詳細は図 7-3, 7-4 がわかりやすい。\n",
    "- フィルター行列の要素値が「どういうフィルタリングをするのか？」を表す。 CNN ではここはパラメータとして、データから学習させる。\n",
    "> [p208] CNN の場合、フィルターのパラメータが、これまでの「重み」に対応 します。そして、CNN の場合もバイアスが存在します。\n",
    "- つまり俗っぽく言うと「職人がこれまで緻密に行ってきたフィルタリングを、AI がデータから自動で行う」みたいなイメージ。特徴量自体を学習する。\n",
    "- 冷静に考えると、次のような違いがあるだけ。\n",
    "  - Affine レイヤ：全ての入力変数の線形結合を何個か作る。fully-connected。\n",
    "  - Conolution レイヤ：隣り合う一部の入力変数だけの線形結合を何個か作る。partially-connected。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フィルタリング後の画像サイズ\n",
    "\n",
    "- パディングを作ってやると、フィルタリング後の画像サイズが小さくなりすぎないようにする。図7-6。そうしないと、ディープにしたときに困る。\n",
    "- 一方、ストライドを大きくすると、フィルタリング後の画像サイズが小さくなる。\n",
    "- つまり結局、出力画像のサイズは以下の３つで決まる。具体的な計算式は (7.1)。このあたりは基本ハイパラで、学習はさせない。\n",
    "  - フィルタ行列のサイズ\n",
    "  - パディングの大きさ\n",
    "  - ストライドの大きさ\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カラー画像 (複数チャネル画像) のフィルタリング\n",
    "\n",
    "- カラー＝複数チャネル画像は、数学的にはランク 3 テンソルで表せる。例えば、256 x 256 の RGB 画像なら、サイズ (3, 256, 256) のテンソル。\n",
    "- CNN の畳み込みでは、入力画像のチャネル数と同じチャネル数のフィルタテンソルを用意して、フィルタリングを行う。図 7-8, 7-9, 7-10。\n",
    "- 出力画像は1チャネルつまり行列 (ランク2テンソル) になる。特徴マップと呼ぶ。\n",
    "- 先ほどと同様に「Affine で fully-connected に作っていた線形結合特徴量を、partially-connected に作るように変更しただけ」とも捉えられる。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 同じ画像に色んなフィルタをかけて色んな特徴取り出す\n",
    "\n",
    "- [このサイト](https://imagingsolution.net/imaging/filter-algorithm/)からわかるように、色んなフィルタリング方法 (フィルタ行列)があって、全然違う特徴が捉えられる。\n",
    "- なので、同じ入力画像に複数のフィルタリングを施すようにした方が、多様な特徴を学習できて良いだろう。そこで、ランク 3 フィルタテンソルをたくさん用意して、１個ずつ入力画像に適用して、それぞれで出力される１枚の画像行列を、チャネル方向に重ねて保持する。図 7-11, 7-12。\n",
    "- ここで「たくさんのランク 3 フィルタテンソル」を「１つのランク 4 フィルタテンソル」として捉えている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バッチ処理\n",
    "\n",
    "- ここまでの説明は全て、１枚の入力画像に対する話。\n",
    "- 複数枚の画像に対して一気に予測する時や、back propagation で勾配計算を行う時には、バッチ処理したくなる。\n",
    "- 入力をランク 4 テンソルと見なす。サイズは (バッチサイズ, チャネル数, 横ピクセル数, 縦ピクセル数) となる。図 7-13。\n",
    "- あとは numpy 等で頑張る。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プーリング層も使う\n",
    "\n",
    "- 画像認識 (例えばイヌネコ分類) に使うことをイメージすると分かるように、なるべく「画像のズレ (微小な平行移動) に対してロバスト (値が変わりづらい)」な特徴量が欲しい。\n",
    "- 学習がとてもうまくいけば、畳み込み層のフィルタで「ズレにロバストな特徴量」が得られる可能性も、一応ある。\n",
    "- が、基本的に常にこのような特徴量は欲しいので、だったら最初からモデルに組み込んでしまえば良い。\n",
    "- それがプーリング層。よく使われるのは、Max プーリング。あるピクセル範囲の最大値を取り出すので、明らかに、画像のズレにロバスト。図 7-14, 7-16。\n",
    "\n",
    "![fig](https://images-tech-blog.s-yoshiki.com/img/2019/05/20190518004109.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution レイヤと Pooling レイヤの比較\n",
    "\n",
    "- どちらも「隣り合うピクセル群から特徴を取り出す」という意味では同じ。\n",
    "- Convolution レイヤでは、フィルタ行列の要素値をパラメータとすることで「どのようなフィルタリングが効果的か？」もデータから学習させる。\n",
    "- Pooling レイヤには、学習するパラメータがない。というか、どういう Pooling　をすべきかをパラメータ化しても良いのだが、事前に「Max プーリングをすればズレにロバストな特徴量が得られて嬉しい」とわかっているので、わざわざ学習させる必要もない。\n",
    "- Convolution レイヤによるフィルタリング後にはチャネル数を 1 にするが、Pooling レイヤではチャネル数をそのままにする。図 7-8 と 図 7-15 を比較。Pooling レイヤでチャネル数を 1 にまとめてしまうと、カラー画像に対して「ズレにロバストな特徴量」にならないから。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN の全体アーキテクチャ\n",
    "\n",
    "- 例えば図 7-2。シンプル NN の「Affine - Activate - ... - Affine - Activate - Affine - Final Activate」という並びの前に 「Convolution - Activate - Pooling」というレイヤセットををいくつか追加したもの。\n",
    "- Pooling を使ったり使わなかったり、細かいバリエーションは色々ある。\n",
    "- Goodfellow本では「１回でも Convolution してれば CNN」 という風にざっくりと定義している。\n",
    "> Convolutional networks are simply neural networks that use convolution in place of general matrix multiplication in at least one of their layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN の実装\n",
    "\n",
    "- フルスクラッチで実装するには...\n",
    "  - back propagation の式を導出。ライプニッツルールをごりごり計算。\n",
    "  - numpy でテンソルをうまく扱う方法を考えて、計算効率をなるべく下げる。\n",
    "- いったん諦めて、PyTorch に頼る。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch で CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### PyTorch のインストール\n",
    "\n",
    "- ちゃんとやるなら、GPU を用意した環境 (各種クラウド、Google Colab など) で動かすべき。今回はローカルでお試し。\n",
    "- [PyTorch 公式](https://pytorch.org/get-started/locally/) で OS やパッケージマネージャを選ぶと、インストールコマンドを作ってくれるので、それをターミナルで実行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリの用意\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (60000, 784)\n",
      "<class 'numpy.ndarray'> (60000,)\n",
      "<class 'numpy.ndarray'> (10000, 784)\n",
      "<class 'numpy.ndarray'> (10000,)\n",
      "<class 'numpy.ndarray'> (20000, 784)\n",
      "<class 'numpy.ndarray'> (20000,)\n",
      "<class 'numpy.ndarray'> (20000, 1, 28, 28) 4\n",
      "<class 'numpy.ndarray'> (10000, 1, 28, 28) 4\n",
      "<class 'torch.Tensor'> torch.Size([20000, 1, 28, 28]) 4\n",
      "<class 'torch.Tensor'> torch.Size([20000]) 1\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 前処理\n",
    "\n",
    "\n",
    "\n",
    "# MNIST の手書き数字画像データセットを読み込み。\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_mnist(normalize=True)\n",
    "\n",
    "print( type(x_train), x_train.shape )\n",
    "print( type(y_train), y_train.shape )\n",
    "print( type(x_test), x_test.shape )\n",
    "print( type(y_test), y_test.shape )\n",
    "\n",
    "\n",
    "\n",
    "# 学習データ 60000 は多すぎるのでサンプリング\n",
    "\n",
    "idx = np.random.choice(len(x_train), 20000, replace=False)\n",
    "x_train = x_train[idx, :]\n",
    "y_train = y_train[idx]\n",
    "\n",
    "print( type(x_train), x_train.shape )\n",
    "print( type(y_train), y_train.shape )\n",
    "\n",
    "\n",
    "\n",
    "# 入力をランク4テンソル (ndim=4 の numpy 配列) に変換。\n",
    "#  shape は (サンプルサイズ, チャネル数, 横ピクセル数, 縦ピクセル数)\n",
    "\n",
    "x_train = x_train.reshape((20000, 1, 28, 28))\n",
    "x_test = x_test.reshape((10000, 1, 28, 28))\n",
    "\n",
    "print( type(x_train), x_train.shape, x_train.ndim)\n",
    "print( type(x_test), x_test.shape, x_test.ndim )\n",
    "\n",
    "\n",
    "\n",
    "# PyTorch 用のデータ構造に変換。\n",
    "\n",
    "BATCH_SIZE = 256    # ミニバッチのサイズを設定。\n",
    "\n",
    "x_train = torch.Tensor(x_train)\n",
    "y_train = torch.Tensor(y_train).long()\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(dataset=train_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "x_test = torch.Tensor(x_test)\n",
    "y_test = torch.Tensor(y_test).long()\n",
    "test_ds = TensorDataset(x_test, y_test)\n",
    "test_dl = DataLoader(dataset=test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "print( type(x_train), x_train.shape, x_train.ndim )\n",
    "print( type(y_train), y_train.shape, y_train.ndim )\n",
    "print( type(train_dl) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CNN モデル (アーキテクチャ) を定義\n",
    "\n",
    "\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "    \"\"\" MNIST 用の CNN\n",
    "    \n",
    "    お試しで作る CNN なので、特に拡張性とか汎用性は気にしない。\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" 初期化\n",
    "        \n",
    "        モデルで使うレイヤをここで定義していく。\n",
    "        torch.nn ライブラリに各種レイヤのテンプレクラスがあるので、そこからインスタンス作る。\n",
    "        レイヤ単位の forward, backward とかはメソッドとして既に記述してくれているので楽。\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        # 継承元の親クラス nn.Module の init を実行。内部の各種設定がされる。\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
    "        # Convolution レイヤ1。\n",
    "        # チャネル数1の入力画像に、サイズ(3,3)の畳み込みフィルタを、16種類適用。\n",
    "        # ストライドはデフォルトで 1, パディングはデフォルトで 0。\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros'\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        # Convolution レイヤ2。\n",
    "        # チャネル数16の入力画像に、サイズ(3,3)の畳み込みフィルタを、32種類適用。\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, stride=2)\n",
    "        # Pooling レイヤ。\n",
    "        # サイズ(2,2)の Max フィルタを、2 ピクセルずつズラしながら適用。\n",
    "        \n",
    "        self.ln1 = nn.Linear(32*5*5, 120)\n",
    "        # Affine レイヤ1。\n",
    "        # 32*5*5次元入力を、120次元に線形変換。\n",
    "        # この入力次元は、↓で Conv　レイヤと Pool レイヤの並びを作る時に、算出して調べる。\n",
    "        \n",
    "        self.ln2 = nn.Linear(120, 10)\n",
    "        # Affine レイヤ2。\n",
    "        # 120 次元入力を、10次元出力に線形変換。\n",
    "        \n",
    "        self.ac = nn.ReLU()\n",
    "        # 活性化関数レイヤ。\n",
    "        # 今回は ReLU を使ってる。\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\" forward propagation\n",
    "        \n",
    "        CNN のアーキテクチャ (レイヤの並び) を定義していく。\n",
    "        \n",
    "        Args:\n",
    "          x: 入力。今回の MNIST では 28 x 28 ピクセルで 1 チャネルの画像。\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.conv1(x)  # 最初に畳み込み\n",
    "        # 入力： 28 x 28 ピクセルで 1 チャネル\n",
    "        # 出力： 26 x 26 ピクセルで 16 チャネル\n",
    "        \n",
    "        x = self.ac(x)  # 活性化\n",
    "        # サイズ変化なし\n",
    "        \n",
    "        x = self.pool(x)  # Max Pooling\n",
    "        # 入力： 26 x 26 ピクセルで 16 チャネル\n",
    "        # 出力： 13 x 13 ピクセルで 16 チャネル\n",
    "        \n",
    "        x = self.conv2(x)  # 再び畳み込み\n",
    "        # 入力： 13 x 13 ピクセルで 16 チャネル\n",
    "        # 出力： 11 x 11 ピクセルで 32 チャネル\n",
    "        \n",
    "        x = self.ac(x)  # 活性化\n",
    "        # サイズ変化なし\n",
    "        \n",
    "        x = self.pool(x)  # 再度 Max Pooling\n",
    "        # 入力： 11 x 11 ピクセルで 32 チャネル\n",
    "        # 出力： 5 x 5 ピクセルで 32 チャネル（11番目の行と列ムシされてる）\n",
    "        \n",
    "        x = x.view(x.size()[0], -1)  # vec\n",
    "        # 入力： 5 x 5 ピクセルで 32 チャネル\n",
    "        # 出力： 5*5*32　次元のベクトル \n",
    "        # これ以前の層で形状に関連する特徴量は捉え尽くしたと考え、テンソルをベクトルに潰す。\n",
    "        \n",
    "        x = self.ln1(x)  # Affine\n",
    "        # 入力： 5*5*32　次元のベクトル\n",
    "        # 出力： 120　次元のベクトル\n",
    "        \n",
    "        x = self.ac(x)  # 活性化\n",
    "        # サイズ変化なし\n",
    "        \n",
    "        x = self.ln2(x)  # Affine\n",
    "        # 入力： 120　次元のベクトル\n",
    "        # 出力： 10　次元のベクトル  (アウトカムが 10 クラスなので)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 訓練を実行する関数\n",
    "\n",
    "def train_fn(model, train_loader, optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    losses = []\n",
    "    ys_pred = []\n",
    "    ys_true = []\n",
    "    \n",
    "    for batch_idx, (xs, ys) in enumerate(train_loader):  # ミニバッチのサンプリング\n",
    "        optimizer.zero_grad()\n",
    "        hs = model(xs)\n",
    "        loss = F.cross_entropy(hs, ys)  # ロス関数にはクロスエントロピーを使用。\n",
    "        loss.backward()\n",
    "        losses += [loss.item()]\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        ys_true += ys.tolist()\n",
    "        ys_pred += hs.argmax(dim=1).tolist()\n",
    "\n",
    "    return np.mean(losses), accuracy_score(ys_true, ys_pred)\n",
    "\n",
    "\n",
    "\n",
    "# テストへの予測を実行する関数\n",
    "\n",
    "def test_fn(model, test_loader, epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    losses = []\n",
    "    ys_pred = []\n",
    "    ys_true = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (xs, ys) in enumerate(test_loader):\n",
    "            hs = model(xs)\n",
    "            loss = F.cross_entropy(hs, ys)\n",
    "            losses += [loss.item()]\n",
    "            \n",
    "            ys_true += ys.tolist()\n",
    "            ys_pred += hs.argmax(dim=1).tolist()\n",
    "\n",
    "    return np.mean(losses), accuracy_score(ys_true, ys_pred)\n",
    "\n",
    "\n",
    "\n",
    "# 「訓練」と「テストデータへの予測評価」を進める関数。\n",
    "\n",
    "def train_test_fn(model, train_loader, test_loader, optimizer, epoch):\n",
    "    \n",
    "    train_loss, train_acc = train_fn(model, train_loader, optimizer, epoch)\n",
    "    test_loss, test_acc = test_fn(model, test_loader, epoch)\n",
    "    print(\n",
    "        f'Epoch: {epoch}',\n",
    "        f'Train Loss: {np.mean(train_loss):.2f}',\n",
    "        f'Train Acc: {train_acc}',\n",
    "        f'Test Loss: {np.mean(test_loss):.2f}',\n",
    "        f'Test Acc: {test_acc}'\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 1.71 Train Acc: 0.52585 Test Loss: 0.77 Test Acc: 0.773\n",
      "Epoch: 1 Train Loss: 0.68 Train Acc: 0.8161 Test Loss: 0.57 Test Acc: 0.8483\n",
      "Epoch: 2 Train Loss: 0.60 Train Acc: 0.83765 Test Loss: 0.53 Test Acc: 0.8645\n",
      "Epoch: 3 Train Loss: 0.56 Train Acc: 0.8515 Test Loss: 0.50 Test Acc: 0.8704\n",
      "Epoch: 4 Train Loss: 0.53 Train Acc: 0.85785 Test Loss: 0.48 Test Acc: 0.878\n",
      "Epoch: 5 Train Loss: 0.50 Train Acc: 0.8702 Test Loss: 0.47 Test Acc: 0.8832\n",
      "Epoch: 6 Train Loss: 0.49 Train Acc: 0.8733 Test Loss: 0.44 Test Acc: 0.8901\n",
      "Epoch: 7 Train Loss: 0.47 Train Acc: 0.8823 Test Loss: 0.44 Test Acc: 0.8923\n",
      "Epoch: 8 Train Loss: 0.46 Train Acc: 0.88495 Test Loss: 0.44 Test Acc: 0.8932\n",
      "Epoch: 9 Train Loss: 0.46 Train Acc: 0.885 Test Loss: 0.43 Test Acc: 0.8963\n",
      "Epoch: 10 Train Loss: 0.45 Train Acc: 0.89025 Test Loss: 0.42 Test Acc: 0.9\n",
      "Epoch: 11 Train Loss: 0.44 Train Acc: 0.89165 Test Loss: 0.42 Test Acc: 0.8979\n",
      "Epoch: 12 Train Loss: 0.44 Train Acc: 0.89255 Test Loss: 0.41 Test Acc: 0.8999\n",
      "Epoch: 13 Train Loss: 0.44 Train Acc: 0.8937 Test Loss: 0.42 Test Acc: 0.8991\n",
      "Epoch: 14 Train Loss: 0.44 Train Acc: 0.89285 Test Loss: 0.41 Test Acc: 0.9039\n",
      "Epoch: 15 Train Loss: 0.43 Train Acc: 0.89445 Test Loss: 0.41 Test Acc: 0.901\n",
      "Epoch: 16 Train Loss: 0.43 Train Acc: 0.89555 Test Loss: 0.41 Test Acc: 0.8992\n",
      "Epoch: 17 Train Loss: 0.43 Train Acc: 0.8966 Test Loss: 0.41 Test Acc: 0.9019\n",
      "Epoch: 18 Train Loss: 0.43 Train Acc: 0.89595 Test Loss: 0.40 Test Acc: 0.9015\n",
      "Epoch: 19 Train Loss: 0.43 Train Acc: 0.89615 Test Loss: 0.41 Test Acc: 0.9004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 訓練 & テストデータ予測評価\n",
    "\n",
    "\n",
    "model = MyCNN()\n",
    "\n",
    "for i in range(20):  # ここが epoch 数。\n",
    "    train_test_fn(\n",
    "        model, train_dl, test_dl,\n",
    "        optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.1), epoch=i\n",
    "    )\n",
    "\n",
    "# optimizer：Adam\n",
    "# 学習率： 0.001\n",
    "# 荷重減衰パラ： 0.1\n",
    "\n",
    "# 普通の NN (fully-connected しかない NN) との比較とか、まだできていない。\n",
    "# 訓練サイズを 1/3 にしたわりには、精度 90 % で良い感じだと思う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
